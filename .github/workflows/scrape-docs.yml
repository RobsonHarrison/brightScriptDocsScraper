name: Scrape Roku Documentation

on:
  # Run weekly on Sundays at 2:00 AM UTC
  schedule:
    - cron: '0 2 * * 0'
  # Allow manual trigger
  workflow_dispatch:

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install crawl4ai
          crawl4ai-setup

      - name: Run scraper
        run: |
          python scraper/WebScraper.py --output-dir ./roku_docs --max-depth 10 --max-pages 2000
        continue-on-error: true  # Don't fail workflow if some pages fail

      - name: Check for changes
        id: changes
        run: |
          git add -A
          if git diff --staged --quiet; then
            echo "has_changes=false" >> $GITHUB_OUTPUT
          else
            echo "has_changes=true" >> $GITHUB_OUTPUT
          fi

      - name: Commit and push changes
        if: steps.changes.outputs.has_changes == 'true'
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git commit -m "docs: update Roku documentation $(date +'%Y-%m-%d')"
          git push

